{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JoshuaLee0816/diffuserlite.github.io/blob/main/01_DiffuserLite_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": "import os\nfrom google.colab import userdata\n\n# === 1. è¨­å®šä½ çš„ GitHub è³‡è¨Š ===\nGITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\nGITHUB_USER = \"JoshuaLee0816\"\nGITHUB_REPO = \"diffuserlite.github.io\"\n\nimport os\nos.chdir('/content')\n\n# === 2. Clone ä½ çš„å€‰åº«ä½œç‚ºã€Œå”¯ä¸€ã€å·¥ä½œç›®éŒ„ ===\n!rm -rf /content/{GITHUB_REPO}\n!git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\n\n# é€²å…¥å€‰åº«\n%cd /content/{GITHUB_REPO}\n\n# === 3. å®‰è£ç’°å¢ƒ ===\n!pip install -e . -q\n!pip install git+https://github.com/Farama-Foundation/D4RL.git --ignore-requires-python -q\n!pip install --upgrade huggingface_hub -q\n\n# å¼·åˆ¶å®‰è£æ­£ç¢ºçš„ numpy ç‰ˆæœ¬ï¼ˆå¿…é ˆåœ¨æœ€å¾Œï¼Œç”¨ --force-reinstallï¼‰\n!pip install numpy==1.26.4 --force-reinstall -q\n\n# MuJoCo 210 å®‰è£\n!mkdir -p /root/.mujoco\n!wget -q https://mujoco.org/download/mujoco210-linux-x86_64.tar.gz -O /tmp/mujoco210.tar.gz\n!tar -xzf /tmp/mujoco210.tar.gz -C /root/.mujoco/\n!apt-get install -qq -y libosmesa6-dev libgl1-mesa-glx libglfw3 patchelf > /dev/null 2>&1\n\n# è¨­å®š Git èº«ä»½\n!git config --global user.email \"310274movie@gmail.com\"\n!git config --global user.name \"JoshuaLee\"\n\nprint(\"=\"*50)\nprint(\"âš ï¸ è«‹åŸ·è¡Œ Runtime â†’ Restart runtime\")\nprint(\"   ç„¶å¾Œå¾ã€ŒHuggingFace ç™»å…¥ã€cell ç¹¼çºŒåŸ·è¡Œ\")\nprint(\"=\"*50)",
   "metadata": {
    "id": "qsneyQzMxrLu"
   },
   "id": "qsneyQzMxrLu",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# === Hugging Face ç™»å…¥ï¼ˆåªéœ€åŸ·è¡Œä¸€æ¬¡ï¼‰===\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=userdata.get('HF_TOKEN'))"
   ],
   "metadata": {
    "id": "wuu_1zDCi2v1"
   },
   "id": "wuu_1zDCi2v1",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c73d0",
   "metadata": {
    "id": "478c73d0"
   },
   "outputs": [],
   "source": "%%writefile /content/run.py\nimport sys, os, types, json, glob, re, time, traceback\nimport mujoco\nimport numpy as np\nimport yaml\n\n# === å¼·åˆ¶ unbuffered output ===\nsys.stdout = os.fdopen(sys.stdout.fileno(), 'w', buffering=1)\nsys.stderr = os.fdopen(sys.stderr.fileno(), 'w', buffering=1)\n\n# === mujoco_py shim ===\nshim = types.ModuleType('mujoco_py')\n\nclass ShimModel:\n    def __init__(self, m):\n        self._m = m\n    @property\n    def actuator_ctrlrange(self):\n        return self._m.actuator_ctrlrange.copy()\n    @property\n    def nq(self): return self._m.nq\n    @property\n    def nv(self): return self._m.nv\n    def __getattr__(self, name):\n        return getattr(self._m, name)\n\nclass ShimData:\n    def __init__(self, d):\n        self._d = d\n    @property\n    def qpos(self): return self._d.qpos\n    @qpos.setter\n    def qpos(self, v): self._d.qpos[:] = v\n    @property\n    def qvel(self): return self._d.qvel\n    @qvel.setter\n    def qvel(self, v): self._d.qvel[:] = v\n    @property\n    def ctrl(self): return self._d.ctrl\n    @ctrl.setter\n    def ctrl(self, v): self._d.ctrl[:] = v\n    def __getattr__(self, name):\n        return getattr(self._d, name)\n\nclass ShimSim:\n    def __init__(self, model):\n        self._m = model._m\n        self._d = mujoco.MjData(self._m)\n        self.model = model\n        self.data = ShimData(self._d)\n    def step(self):\n        mujoco.mj_step(self._m, self._d)\n    def forward(self):\n        mujoco.mj_forward(self._m, self._d)\n    def get_state(self):\n        return type('S',(),{'time':self._d.time,'qpos':self._d.qpos.copy(),'qvel':self._d.qvel.copy(),'act':np.array([]),'udd_state':{}})()\n    def set_state(self, s):\n        self._d.time = s.time\n        self._d.qpos[:] = s.qpos\n        self._d.qvel[:] = s.qvel\n        mujoco.mj_forward(self._m, self._d)\n\nclass MjViewer:\n    def __init__(self, sim): pass\n    def render(self): pass\n\nshim.load_model_from_path = lambda p: ShimModel(mujoco.MjModel.from_xml_path(p))\nshim.MjSim = lambda m: ShimSim(m)\nshim.MjViewer = MjViewer\nshim.MujocoException = Exception\nshim.ignore_mujoco_warnings = type('ctx',(),{'__enter__':lambda s:None,'__exit__':lambda s,*a:None})\nshim.__path__ = []\nfor sub in ['cymj','builder','generated','generated.const']:\n    sys.modules[f'mujoco_py.{sub}'] = types.ModuleType(f'mujoco_py.{sub}')\nsys.modules['mujoco_py'] = shim\n\n# === è¨­å®šè·¯å¾‘ ===\nos.chdir('/content/diffuserlite.github.io')\nos.makedirs('results/figures', exist_ok=True)\n\n# === è®€å–ç’°å¢ƒåç¨± ===\nwith open('configs/diffuserlite/mujoco/mujoco.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\ndefaults = config.get('defaults', [])\nENV_NAME = 'halfcheetah-medium-expert-v2'\nfor item in defaults:\n    if isinstance(item, dict) and 'task' in item:\n        ENV_NAME = item['task']\n        break\n\nprint(f\"ğŸ® è¨“ç·´ç’°å¢ƒ: {ENV_NAME}\")\nsys.stdout.flush()\n\n# === å¾ HuggingFace ä¸‹è¼‰ä¹‹å‰çš„ loss_log.json ===\noriginal_print = print\nloss_log = []\nloss_log_path = f'results/loss_log_{ENV_NAME}.json'\n\ntry:\n    from huggingface_hub import hf_hub_download\n    repo_id = \"JoshuaLee0816/diffuserlite-results\"\n    local_path = hf_hub_download(repo_id=repo_id, filename=f\"loss_log_{ENV_NAME}.json\")\n    with open(local_path, 'r') as f:\n        loss_log = json.load(f)\n    original_print(f\"âœ… å¾ HuggingFace è¼‰å…¥ {len(loss_log)} ç­†æ­·å²è¨˜éŒ„\")\n    if loss_log:\n        original_print(f\"   ä¸Šæ¬¡è¨“ç·´åˆ°ç¬¬ {loss_log[-1].get('gradient_steps', 0)} æ­¥\")\nexcept Exception as e:\n    original_print(f\"âš ï¸ ç„¡æ³•è¼‰å…¥æ­·å²è¨˜éŒ„ï¼Œå°‡å¾é ­é–‹å§‹\")\n\nsys.stdout.flush()\n\nwith open(loss_log_path, 'w') as f:\n    json.dump(loss_log, f)\n\n# === HuggingFace ä¸Šå‚³å‡½æ•¸ ===\ndef upload_single_file_with_retry(api, local_path, repo_path, repo_id, max_retries=5):\n    for attempt in range(max_retries):\n        try:\n            api.upload_file(path_or_fileobj=local_path, path_in_repo=repo_path, repo_id=repo_id)\n            return True\n        except Exception as e:\n            if \"rate limit\" in str(e).lower() or \"429\" in str(e):\n                wait_time = 60 * (attempt + 1)\n                original_print(f\"  â³ Rate limitï¼Œç­‰å¾… {wait_time} ç§’...\")\n                time.sleep(wait_time)\n            else:\n                if attempt < max_retries - 1:\n                    time.sleep(30)\n                else:\n                    return False\n    return False\n\ndef upload_to_hf(files_to_upload, message=\"\"):\n    try:\n        from huggingface_hub import HfApi\n        api = HfApi()\n        repo_id = \"JoshuaLee0816/diffuserlite-results\"\n        success = 0\n        for local_path, repo_path in files_to_upload:\n            if os.path.exists(local_path):\n                if upload_single_file_with_retry(api, local_path, repo_path, repo_id):\n                    success += 1\n                time.sleep(2)\n        if message and success > 0:\n            original_print(f\"ğŸ“¤ {message} ({success}/{len(files_to_upload)} æª”æ¡ˆ)\")\n    except Exception as e:\n        original_print(f\"âš ï¸ ä¸Šå‚³å¤±æ•—: {e}\")\n\ndef cleanup_old_checkpoints(checkpoint_dir):\n    try:\n        for prefix in ['diffusion0', 'diffusion1', 'diffusion2', 'invdyn']:\n            for f in glob.glob(os.path.join(checkpoint_dir, f'{prefix}_ckpt_*.pt')):\n                if 'latest' not in f:\n                    match = re.search(r'_ckpt_(\\d+)\\.pt', f)\n                    if match and int(match.group(1)) % 5000 != 1000:\n                        os.remove(f)\n    except:\n        pass\n\ndef delete_from_hf(files_to_delete):\n    try:\n        from huggingface_hub import HfApi\n        api = HfApi()\n        for path in files_to_delete:\n            try:\n                api.delete_file(path_in_repo=path, repo_id=\"JoshuaLee0816/diffuserlite-results\")\n                time.sleep(1)\n            except:\n                pass\n    except:\n        pass\n\ndef update_figure():\n    import matplotlib.pyplot as plt\n    if not loss_log:\n        return\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    steps = [d['gradient_steps'] for d in loss_log]\n    for key in ['loss0', 'loss1', 'loss2']:\n        if key in loss_log[0]:\n            axes[0].plot(steps, [d[key] for d in loss_log], label=key, alpha=0.8)\n    axes[0].set_xlabel('Gradient Steps')\n    axes[0].set_ylabel('Loss')\n    axes[0].set_title(f'Diffusion Model Loss ({ENV_NAME})')\n    axes[0].legend()\n    axes[0].grid(True)\n    if 'invdyn_loss' in loss_log[0]:\n        axes[1].plot(steps, [d['invdyn_loss'] for d in loss_log], color='orange', alpha=0.8)\n        axes[1].set_xlabel('Gradient Steps')\n        axes[1].set_ylabel('Loss')\n        axes[1].set_title(f'Inverse Dynamics Loss ({ENV_NAME})')\n        axes[1].grid(True)\n    plt.tight_layout()\n    plt.savefig(f'results/figures/loss_curve_{ENV_NAME}.png', dpi=150)\n    plt.close()\n\n# === æ””æˆª print ä¾†è¨˜éŒ„ loss ===\nlast_upload_step = 0\ncheckpoint_dir = f'results/diffuserlite_d4rl_mujoco/{ENV_NAME}'\nhf_prefix = f'diffuserlite_d4rl_mujoco/{ENV_NAME}'\n\ndef custom_print(*args, **kwargs):\n    global last_upload_step\n    original_print(*args, **kwargs)\n    sys.stdout.flush()\n    \n    if args and isinstance(args[0], dict) and 'gradient_steps' in args[0]:\n        current_step = args[0]['gradient_steps']\n        loss_log.append(args[0].copy())\n        with open(loss_log_path, 'w') as f:\n            json.dump(loss_log, f)\n        \n        if current_step - last_upload_step >= 1000:\n            update_figure()\n            files = [\n                (loss_log_path, f'loss_log_{ENV_NAME}.json'),\n                (f'results/figures/loss_curve_{ENV_NAME}.png', f'figures/loss_curve_{ENV_NAME}.png'),\n            ]\n            for name in ['diffusion0', 'diffusion1', 'diffusion2', 'invdyn']:\n                for suffix in ['latest', str(current_step)]:\n                    path = f'{checkpoint_dir}/{name}_ckpt_{suffix}.pt'\n                    if os.path.exists(path):\n                        files.append((path, f'{hf_prefix}/{name}_ckpt_{suffix}.pt'))\n            \n            upload_to_hf(files, f\"å·²ä¸Šå‚³ step {current_step}\")\n            \n            if current_step % 5000 != 1000 and last_upload_step > 0:\n                delete_from_hf([f'{hf_prefix}/{n}_ckpt_{last_upload_step}.pt' for n in ['diffusion0','diffusion1','diffusion2','invdyn']])\n            cleanup_old_checkpoints(checkpoint_dir)\n            last_upload_step = current_step\n\nimport builtins\nbuiltins.print = custom_print\n\n# === åŸ·è¡Œè¨“ç·´ ===\noriginal_print(\"ğŸš€ é–‹å§‹è¨“ç·´...\")\nsys.stdout.flush()\n\ntry:\n    import runpy\n    runpy.run_path('pipelines/diffuserlite_d4rl_mujoco.py', run_name='__main__')\nexcept SystemExit as e:\n    if e.code != 0:\n        original_print(f\"\\nâŒ è¨“ç·´ç•°å¸¸çµæŸ (code {e.code})\")\nexcept Exception as e:\n    original_print(f\"\\nâŒ è¨“ç·´éŒ¯èª¤:\\n{traceback.format_exc()}\")\n    sys.exit(1)\n\n# === æœ€çµ‚ä¸Šå‚³ ===\noriginal_print(\"\\n\" + \"=\"*50)\noriginal_print(f\"âœ… è¨“ç·´å®Œæˆï¼({ENV_NAME})\")\nupdate_figure()\nfiles = [(loss_log_path, f'loss_log_{ENV_NAME}.json'), (f'results/figures/loss_curve_{ENV_NAME}.png', f'figures/loss_curve_{ENV_NAME}.png')]\nfor name in ['diffusion0', 'diffusion1', 'diffusion2', 'invdyn']:\n    path = f'{checkpoint_dir}/{name}_ckpt_latest.pt'\n    if os.path.exists(path):\n        files.append((path, f'{hf_prefix}/{name}_ckpt_latest.pt'))\nupload_to_hf(files, \"æœ€çµ‚çµæœå·²ä¸Šå‚³\")\noriginal_print(\"=\"*50)"
  },
  {
   "cell_type": "markdown",
   "id": "n8uivn9znm",
   "source": "# ============================================================\n# æ–·ç·šæ¢å¾©ï¼šå¾ HuggingFace ä¸‹è¼‰ checkpoint\n# ============================================================\n# å¦‚æœ Colab æ–·ç·šï¼Œé‡æ–°åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š\n# 1. åŸ·è¡Œã€Œç’°å¢ƒå®‰è£ã€cell\n# 2. åŸ·è¡Œã€ŒHuggingFace ç™»å…¥ã€cell\n# 3. åŸ·è¡Œã€Œå¾ HuggingFace ä¸‹è¼‰ checkpointã€cellï¼ˆä¸‹æ–¹ï¼‰\n# 4. åŸ·è¡Œã€Œè¨­å®šè¨“ç·´åƒæ•¸ã€cell\n# 5. åŸ·è¡Œã€ŒåŸ·è¡Œè¨“ç·´ã€cell",
   "metadata": {
    "id": "n8uivn9znm"
   }
  },
  {
   "cell_type": "code",
   "id": "om82o0w2ff",
   "source": "# === å¾ Hugging Face ä¸‹è¼‰ä¹‹å‰çš„ checkpointï¼ˆæ–·ç·šæ¢å¾©ç”¨ï¼‰===\nfrom huggingface_hub import hf_hub_download, list_repo_files\nimport os\nimport shutil\nimport json\n\nrepo_id = \"JoshuaLee0816/diffuserlite-results\"\nlocal_results_dir = '/content/diffuserlite.github.io/results/diffuserlite_d4rl_mujoco/halfcheetah-medium-expert-v2'\n\n# æª¢æŸ¥ Hugging Face ä¸Šæœ‰æ²’æœ‰ä¹‹å‰çš„ checkpoint\ntry:\n    files = list_repo_files(repo_id)\n    \n    # 1. ä¸‹è¼‰ checkpoint\n    checkpoint_files = [f for f in files if 'halfcheetah-medium-expert-v2' in f and 'latest' in f and f.endswith('.pt')]\n    \n    if checkpoint_files:\n        print(f\"æ‰¾åˆ° {len(checkpoint_files)} å€‹ checkpoint æª”æ¡ˆï¼Œé–‹å§‹ä¸‹è¼‰...\")\n        os.makedirs(local_results_dir, exist_ok=True)\n\n        for f in checkpoint_files:\n            local_path = hf_hub_download(repo_id=repo_id, filename=f)\n            filename = os.path.basename(f)\n            dest_path = os.path.join(local_results_dir, filename)\n            shutil.copy(local_path, dest_path)\n            print(f\"  âœ… {filename}\")\n        print(f\"\\nâœ… å·²å¾ Hugging Face æ¢å¾© checkpointï¼\")\n    else:\n        print(\"âš ï¸ Hugging Face ä¸Šæ²’æœ‰æ‰¾åˆ° checkpointï¼Œå°‡å¾é ­é–‹å§‹è¨“ç·´\")\n    \n    # 2. ä¸‹è¼‰ loss_log.jsonï¼ˆç”¨æ–¼æ¥çºŒåœ–è¡¨ï¼‰\n    if 'loss_log.json' in files:\n        local_path = hf_hub_download(repo_id=repo_id, filename=\"loss_log.json\")\n        dest_path = '/content/diffuserlite.github.io/results/loss_log.json'\n        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n        shutil.copy(local_path, dest_path)\n        \n        with open(dest_path, 'r') as f:\n            loss_log = json.load(f)\n        if loss_log:\n            last_step = loss_log[-1].get('gradient_steps', 0)\n            print(f\"âœ… å·²æ¢å¾© loss_log.jsonï¼ˆ{len(loss_log)} ç­†è¨˜éŒ„ï¼Œä¸Šæ¬¡åˆ°ç¬¬ {last_step} æ­¥ï¼‰\")\n    else:\n        print(\"âš ï¸ æ²’æœ‰æ‰¾åˆ° loss_log.jsonï¼Œå°‡å¾é ­é–‹å§‹è¨˜éŒ„\")\n        \nexcept Exception as e:\n    print(f\"âš ï¸ ç„¡æ³•é€£æ¥ Hugging Face: {e}\")\n    print(\"   å°‡å¾é ­é–‹å§‹è¨“ç·´\")\n\n# é¡¯ç¤ºç›®å‰æœ¬åœ°çš„ checkpoint\nprint(f\"\\n=== æœ¬åœ° checkpoint ç‹€æ…‹ ===\")\nif os.path.exists(local_results_dir):\n    files = os.listdir(local_results_dir)\n    latest_files = [f for f in files if 'latest' in f]\n    if latest_files:\n        for f in sorted(latest_files):\n            size_mb = os.path.getsize(os.path.join(local_results_dir, f)) / (1024*1024)\n            print(f\"  {f}: {size_mb:.1f} MB\")\n    else:\n        print(\"  (ç„¡ checkpoint)\")\nelse:\n    print(\"  (ç›®éŒ„ä¸å­˜åœ¨)\")",
   "metadata": {
    "id": "om82o0w2ff"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# === éšæ®µ 1ï¼šè¨­å®šæ­£å¼è¨“ç·´åƒæ•¸ ===\n# è¨“ç·´ 100,000 æ­¥ï¼Œæ¯ 1000 æ­¥å­˜ checkpoint\n\n!sed -i 's/save_interval: [0-9]*/save_interval: 1000/' /content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml\n!sed -i 's/diffusion_gradient_steps: [0-9]*/diffusion_gradient_steps: 100000/' /content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml\n!sed -i 's/invdyn_gradient_steps: [0-9]*/invdyn_gradient_steps: 100000/' /content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml\n!sed -i 's/log_interval: [0-9]*/log_interval: 100/' /content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml\n\n# ç¢ºèªä¿®æ”¹çµæœ\n!echo \"=== æ­£å¼è¨“ç·´åƒæ•¸ï¼ˆ100K æ­¥ï¼‰===\"\n!grep -E \"save_interval|diffusion_gradient_steps|invdyn_gradient_steps|log_interval|device:\" /content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml",
   "metadata": {
    "id": "CtmBq_jJddyV"
   },
   "id": "CtmBq_jJddyV",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fj14teps15v",
   "source": "# ============================================================\n# ç’°å¢ƒé¸æ“‡ï¼ˆä¸‰é¸ä¸€åŸ·è¡Œï¼‰\n# ============================================================\n# é è¨­æ˜¯ halfcheetahï¼Œå¦‚æœè¦è·‘å…¶ä»–ç’°å¢ƒï¼ŒåŸ·è¡Œå°æ‡‰çš„ cell\n# \n# | ç’°å¢ƒ | è«–æ–‡ R1 åˆ†æ•¸ |\n# |------|-------------|\n# | halfcheetah-medium-expert-v2 | 91.9 |\n# | walker2d-medium-expert-v2 | 109.1 |\n# | hopper-medium-expert-v2 | 103.3 |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "et1yguepctk",
   "source": "# === é¸æ“‡ç’°å¢ƒï¼šHalfCheetahï¼ˆé è¨­ï¼‰===\nENV_NAME = \"halfcheetah-medium-expert-v2\"\n\nimport subprocess\nsubprocess.run(['sed', '-i', f's/task: .*/task: {ENV_NAME}/', '/content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml'])\nprint(f\"âœ… å·²è¨­å®šç’°å¢ƒ: {ENV_NAME}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ih9g1rbolw",
   "source": "# === é¸æ“‡ç’°å¢ƒï¼šWalker2d ===\nENV_NAME = \"walker2d-medium-expert-v2\"\n\nimport subprocess\nsubprocess.run(['sed', '-i', f's/task: .*/task: {ENV_NAME}/', '/content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml'])\nprint(f\"âœ… å·²è¨­å®šç’°å¢ƒ: {ENV_NAME}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2po45b0fn0x",
   "source": "# === é¸æ“‡ç’°å¢ƒï¼šHopper ===\nENV_NAME = \"hopper-medium-expert-v2\"\n\nimport subprocess\nsubprocess.run(['sed', '-i', f's/task: .*/task: {ENV_NAME}/', '/content/diffuserlite.github.io/configs/diffuserlite/mujoco/mujoco.yaml'])\nprint(f\"âœ… å·²è¨­å®šç’°å¢ƒ: {ENV_NAME}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# === åŸ·è¡Œè¨“ç·´ï¼ˆ100K æ­¥ï¼‰===\n# æœƒè‡ªå‹•ï¼š\n# 1. å¾ HuggingFace ä¸‹è¼‰ä¹‹å‰çš„ loss_log.jsonï¼ˆæ¥çºŒåœ–è¡¨ï¼‰\n# 2. æ¯ 1000 æ­¥ä¸Šå‚³ checkpoint å’Œåœ–è¡¨åˆ° HuggingFace\n# 3. åªä¿ç•™ 1000, 6000, 11000, 16000... æ­¥çš„ checkpointï¼ˆé–“éš” 5000 æ­¥ï¼‰\n#    é€™æ¨£å¯ä»¥åœ¨æ¨è«–æ™‚çœ‹åˆ°å­¸ç¿’éç¨‹\n\n!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco210/bin && python3 /content/run.py",
   "metadata": {
    "id": "qNegtm29aNAn"
   },
   "id": "qNegtm29aNAn",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "j951k572nng",
   "source": "# === ç¢ºèª checkpoint ç‹€æ…‹ï¼ˆå¯é¸ï¼‰===\nimport os\nimport json\n\ncheckpoint_dir = '/content/diffuserlite.github.io/results/diffuserlite_d4rl_mujoco/halfcheetah-medium-expert-v2'\nloss_log_path = '/content/diffuserlite.github.io/results/loss_log.json'\n\nprint(\"=== Checkpoint ç‹€æ…‹ ===\")\nif os.path.exists(checkpoint_dir):\n    files = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')])\n    for f in files:\n        filepath = os.path.join(checkpoint_dir, f)\n        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n        print(f\"  {f}: {size_mb:.1f} MB\")\nelse:\n    print(\"  (ç„¡ checkpoint)\")\n\nprint(\"\\n=== Loss Log ç‹€æ…‹ ===\")\nif os.path.exists(loss_log_path):\n    with open(loss_log_path, 'r') as f:\n        loss_log = json.load(f)\n    if loss_log:\n        print(f\"  å…± {len(loss_log)} ç­†è¨˜éŒ„\")\n        print(f\"  æœ€æ–°æ­¥æ•¸: {loss_log[-1].get('gradient_steps', 0)}\")\n    else:\n        print(\"  (ç©ºçš„)\")\nelse:\n    print(\"  (ä¸å­˜åœ¨)\")",
   "metadata": {
    "id": "j951k572nng"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3donmbmis98",
   "source": "# === æ‰‹å‹•ä¸Šå‚³åˆ° HuggingFaceï¼ˆå‚™ä»½ç”¨ï¼Œä¸€èˆ¬ä¸éœ€è¦åŸ·è¡Œï¼‰===\n# è¨“ç·´è…³æœ¬å·²è‡ªå‹•æ¯ 1000 æ­¥ä¸Šå‚³ï¼Œé€™è£¡åªæ˜¯å‚™ä»½é¸é …\n\nfrom huggingface_hub import HfApi\nimport os\nimport glob\n\napi = HfApi()\nrepo_id = \"JoshuaLee0816/diffuserlite-results\"\n\nprint(\"æ­£åœ¨æ‰‹å‹•ä¸Šå‚³åˆ° Hugging Face...\")\n\nfiles_to_upload = [\n    ('/content/diffuserlite.github.io/results/loss_log.json', 'loss_log.json'),\n    ('/content/diffuserlite.github.io/results/figures/loss_curve.png', 'figures/loss_curve.png'),\n]\n\ncheckpoint_dir = '/content/diffuserlite.github.io/results/diffuserlite_d4rl_mujoco/halfcheetah-medium-expert-v2'\nfor name in ['diffusion0', 'diffusion1', 'diffusion2', 'invdyn']:\n    ckpt_path = f'{checkpoint_dir}/{name}_ckpt_latest.pt'\n    if os.path.exists(ckpt_path):\n        files_to_upload.append((ckpt_path, f'diffuserlite_d4rl_mujoco/halfcheetah-medium-expert-v2/{name}_ckpt_latest.pt'))\n\nfor local_path, repo_path in files_to_upload:\n    if os.path.exists(local_path):\n        try:\n            api.upload_file(\n                path_or_fileobj=local_path,\n                path_in_repo=repo_path,\n                repo_id=repo_id,\n            )\n            print(f\"  âœ… {repo_path}\")\n        except Exception as e:\n            print(f\"  âŒ {repo_path}: {e}\")\n\nprint(f\"\\nâœ… ä¸Šå‚³å®Œæˆï¼\")\nprint(f\"ğŸ”— https://huggingface.co/{repo_id}\")",
   "metadata": {
    "id": "3donmbmis98"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}